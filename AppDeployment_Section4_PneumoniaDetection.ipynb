{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/htn5400/Pneumonia-Detection/blob/main/AppDeployment_Section4_PneumoniaDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploying our Pneumonia Detection App"
      ],
      "metadata": {
        "id": "_miIJNrJE3X4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://journals.plos.org/plosone/article/figure/image?size=medium&id=10.1371/journal.pone.0256630.g014)"
      ],
      "metadata": {
        "id": "msrdSfotHqbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our model trained and set up, we can deploy it as a full scale application to the web! While your site is running, you'll be able to use it on your laptop or computer or share it with friends! We'll be using [Streamlit](https://www.streamlit.io/), a library of website objects and methods that allows us to quickly build a site."
      ],
      "metadata": {
        "id": "FYrI1YrYFHde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1. Streamlit - Deploying your model to the web\n",
        "\n",
        "The goal of this session is to learn how to deploy the models that we have been training to the web so they can be shared with the world!\n",
        "\n",
        "Take a moment to look through examples of websites built with Streamlit [here](https://streamlit.io/gallery?category=favorites). As a class, choose your favorite and answer the following **questions:**\n",
        "* Who is this application for?\n",
        "* How does the user input data - are these intuitive ways of interacting with the app?\n",
        "* What does the application do with the data?\n",
        "* Evaluate the ease of use and look of the application.\n",
        "\n",
        "\n",
        "Now that we've seen what is possible with Streamlit, let's try to deploy our **pneumonia detection model** to the web!"
      ],
      "metadata": {
        "id": "6cjHGzmBl_Vh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Od_JMBPjfPv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run this to download data and prepare our environment!\n",
        "# %tensorflow_version 1.x\n",
        "\n",
        "!pip -q install streamlit > /dev/null\n",
        "!pip -q install pyngrok > /dev/null\n",
        "!pip install scikeras > /dev/null\n",
        "\n",
        "import scikeras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import gdown\n",
        "import cv2\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from pyngrok import ngrok\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.regularizers import l2\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from imgaug import augmenters\n",
        "def augment(data, augmenter):\n",
        "  if len(data.shape) == 3:\n",
        "    return augmenter.augment_image(data)\n",
        "  if len(data.shape) == 4:\n",
        "    return augmenter.augment_images(data)\n",
        "\n",
        "def rotate(data, rotate):\n",
        "  fun = augmenters.Affine(rotate = rotate)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def shear(data, shear):\n",
        "  fun = augmenters.Affine(shear = shear)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def scale(data, scale):\n",
        "  fun = augmenters.Affine(scale = scale)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def flip_left_right(data, prob):\n",
        "  fun = augmenters.Fliplr(p = prob)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def flip_up_down(data, prob):\n",
        "  fun = augmenters.Flipud(p = prob)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def remove_color(data, channel):\n",
        "  new_data = data.copy()\n",
        "  if len(data.shape) == 3:\n",
        "    new_data[:,:,channel] = 0\n",
        "    return new_data\n",
        "  if len(data.shape) == 4:\n",
        "    new_data[:,:,:,channel] = 0\n",
        "    return new_data\n",
        "\n",
        "class pkg:\n",
        "  #### DOWNLOADING AND LOADING DATA\n",
        "  def get_metadata(metadata_path, which_splits = ['train', 'test']):\n",
        "    '''returns metadata dataframe which contains columns of:\n",
        "       * index: index of data into numpy data\n",
        "       * class: class of image\n",
        "       * split: which dataset split is this a part of?\n",
        "    '''\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    keep_idx = metadata['split'].isin(which_splits)\n",
        "    return metadata[keep_idx]\n",
        "\n",
        "  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n",
        "    '''\n",
        "    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n",
        "    flattens if flatten option is True\n",
        "    '''\n",
        "    sub_df = metadata[metadata['split'].isin([split_name])]\n",
        "    index  = sub_df['index'].values\n",
        "    labels = sub_df['class'].values\n",
        "    data = all_data[index,:]\n",
        "    if flatten:\n",
        "      data = data.reshape([-1, np.product(image_shape)])\n",
        "    return data, labels\n",
        "\n",
        "  def get_train_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('train', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_test_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('test', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_field_data(flatten, all_data, metadata, image_shape):\n",
        "    field_data, field_labels = get_data_split('field', flatten, all_data, metadata, image_shape)\n",
        "    field_data[:,:,:,2] = field_data[:,:,:,0]\n",
        "    field_data[:,:,:,1] = field_data[:,:,:,0]\n",
        "\n",
        "    #make data messier\n",
        "    rand = random.uniform(-1, 1)\n",
        "\n",
        "    for i in range(len(field_data)):\n",
        "      image = field_data[i]\n",
        "\n",
        "      if abs(rand) < 0.5:\n",
        "        image = rotate(image, rotate = rand * 40)\n",
        "      elif abs(rand) < 0.8:\n",
        "        image = shear(image, shear = rand*40)\n",
        "      field_data[i] = image\n",
        "    return field_data, field_labels\n",
        "\n",
        "class helpers:\n",
        "  #### PLOTTING\n",
        "  def plot_one_image(data, labels = [], index = None, image_shape = [64,64,3]):\n",
        "    '''\n",
        "    if data is a single image, display that image\n",
        "\n",
        "    if data is a 4d stack of images, display that image\n",
        "    '''\n",
        "    num_dims   = len(data.shape)\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    # reshape data if necessary\n",
        "    if num_dims == 1:\n",
        "      data = data.reshape(target_shape)\n",
        "    if num_dims == 2:\n",
        "      data = data.reshape(np.vstack[-1, image_shape])\n",
        "    num_dims   = len(data.shape)\n",
        "\n",
        "    # check if single or multiple images\n",
        "    if num_dims == 3:\n",
        "      if num_labels > 1:\n",
        "        print('Multiple labels does not make sense for single image.')\n",
        "        return\n",
        "\n",
        "      label = labels\n",
        "      if num_labels == 0:\n",
        "        label = ''\n",
        "      image = data\n",
        "\n",
        "    if num_dims == 4:\n",
        "      image = data[index, :]\n",
        "      label = labels[index]\n",
        "\n",
        "    # plot image of interest\n",
        "    print('Label: %s'%label)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "  #### QUERYING AND COMBINING DATA\n",
        "  def combine_data(data_list, labels_list):\n",
        "    return np.concatenate(data_list, axis = 0), np.concatenate(labels_list, axis = 0)\n",
        "\n",
        "  def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    # i'm sorry for this function's code. i am so sorry.\n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')\n",
        "    ax.legend(loc = 4)\n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "class models:\n",
        "  def DenseClassifier(hidden_layer_sizes, nn_params):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape = nn_params['input_shape']))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    for ilayer in hidden_layer_sizes:\n",
        "      model.add(Dense(ilayer, activation = 'relu'))\n",
        "      model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=keras.optimizers.SGD(learning_rate=1e-4, momentum=0.95),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def CNNClassifier(num_hidden_layers, nn_params):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=nn_params['input_shape'], padding = 'same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    for i in range(num_hidden_layers-1):\n",
        "        model.add(Conv2D(64, (3, 3), padding = 'same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(units = 128, activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units = 64, activation = 'relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.legacy.RMSprop(learning_rate=1e-5, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def TransferClassifier(name, nn_params, trainable = False):\n",
        "    expert_dict = {'VGG16': VGG16,\n",
        "                   'VGG19': VGG19,\n",
        "                   'ResNet50':ResNet50,\n",
        "                   'DenseNet121':DenseNet121}\n",
        "\n",
        "    expert_conv = expert_dict[name](weights = 'imagenet',\n",
        "                                              include_top = False,\n",
        "                                              input_shape = nn_params['input_shape'])\n",
        "    for layer in expert_conv.layers:\n",
        "      layer.trainable = trainable\n",
        "\n",
        "    expert_model = Sequential()\n",
        "    expert_model.add(expert_conv)\n",
        "    expert_model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    expert_model.add(Dense(128, activation = 'relu'))\n",
        "    # expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(64, activation = 'relu'))\n",
        "    # expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    expert_model.compile(loss = nn_params['loss'],\n",
        "                  optimizer = keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return expert_model\n",
        "\n",
        "### defining project variables\n",
        "# file variables\n",
        "metadata_url         = \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/metadata.csv\"\n",
        "image_data_url       = 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/image_data.npy'\n",
        "image_data_path      = './image_data.npy'\n",
        "metadata_path        = './metadata.csv'\n",
        "image_shape          = (64, 64, 3)\n",
        "\n",
        "# neural net parameters\n",
        "nn_params = {}\n",
        "nn_params['input_shape']       = image_shape\n",
        "nn_params['output_neurons']    = 1\n",
        "nn_params['loss']              = 'binary_crossentropy'\n",
        "nn_params['output_activation'] = 'sigmoid'\n",
        "\n",
        "###\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/metadata.csv\"\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/image_data.npy\"\n",
        "\n",
        "\n",
        "### pre-loading all data of interest\n",
        "_all_data = np.load('image_data.npy')\n",
        "_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n",
        "\n",
        "### preparing definitions\n",
        "# downloading and loading data\n",
        "get_data_split = pkg.get_data_split\n",
        "get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n",
        "get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_field_data  = lambda flatten = False : pkg.get_field_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "\n",
        "# plotting\n",
        "plot_one_image = lambda data, labels = [], index = None: helpers.plot_one_image(data = data, labels = labels, index = index, image_shape = image_shape);\n",
        "plot_acc       = lambda history: helpers.plot_acc(history)\n",
        "\n",
        "# querying and combining data\n",
        "combine_data           = helpers.combine_data;\n",
        "\n",
        "# models with input parameters\n",
        "DenseClassifier     = lambda hidden_layer_sizes: models.DenseClassifier(hidden_layer_sizes = hidden_layer_sizes, nn_params = nn_params);\n",
        "CNNClassifier       = lambda num_hidden_layers: models.CNNClassifier(num_hidden_layers, nn_params = nn_params);\n",
        "TransferClassifier  = lambda name: models.TransferClassifier(name = name, nn_params = nn_params);\n",
        "\n",
        "monitor = ModelCheckpoint('./model.h5', monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "def launch_website():\n",
        "  print (\"Click this link to try your web app:\")\n",
        "  if (ngrok.get_tunnels() != None):\n",
        "    ngrok.kill()\n",
        "  public_url = ngrok.connect()\n",
        "  print (public_url)\n",
        "  !streamlit run --server.port 80 app.py >/dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=SlateGrey><h2><b>\n",
        "Use [these](https://drive.google.com/file/d/12zwuOuKh91VSHIHS-6S4ADF4HLC2wKJq/view?usp=sharing) instructions to create a ngrok account and get your authtoken!\n",
        "</b></h2></font>\n",
        "\n",
        "<font color=DarkGray><h3><b>\n",
        "Paste your authtoken below next to `!ngrok authtoken`!\n",
        "</b></h3></font>"
      ],
      "metadata": {
        "id": "TMAuRFOklx31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken # YOUR AUTH TOKEN HERE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvmMKgftlz5j",
        "outputId": "fc2c3893-aee0-4a12-b9a0-0a24a54f66e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Making a website with streamlit\n",
        "\n",
        "Streamlit interprets Python files as a website! This is great for several reasons\n",
        "* No need to know HTML, CSS, Javascript,... etc\n",
        "* Easy to use our trained models which are already in Python!\n",
        "\n",
        "We'll write everything to a file called app.py, which is used for Streamlit to launch the site.\n"
      ],
      "metadata": {
        "id": "GJLm_hnPmMM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"Pneumonia Detection\")\n",
        "st.header(\"Description of the app\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZJP9IQOmvV8",
        "outputId": "8fee986d-7ecf-451f-d968-03d15e253f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "#Publish Web App (Run this again whenever you make changes)\n",
        "launch_website()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z21OHfkXl82E",
        "outputId": "be00ca5e-299c-48ea-a321-3c77fc76269e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-07-14T15:03:59+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://24cd-35-229-156-49.ngrok-free.app\" -> \"http://localhost:80\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:80\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.229.156.49:80\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Loading the model\n",
        "\n",
        "Since the focus of this session is deployment we'll skip over training the model and just load one that we've already trained :)\n",
        "\n",
        "Here is a reference on how to save and load sklearn and tensorflow models!\n",
        "\n",
        "For sklearn:\n",
        "```\n",
        "from joblib import dump, load\n",
        "\n",
        "# ====== Save model ========\n",
        "dump(model, 'filename.joblib')\n",
        "\n",
        "# ====== Load model ========\n",
        "clf = load('filename.joblib')\n",
        "```\n",
        "\n",
        "For tensorflow:\n",
        "```\n",
        "import tensorflow as tf\n",
        "\n",
        "# ====== Save model ========\n",
        "model.save(\"filename.h5\")\n",
        "\n",
        "# ====== Load model ========\n",
        "tf.keras.models.load_model(\"filename.h5\")\n",
        "```\n",
        "\n",
        "Our model today is going to be a tensorflow model! Let's load in the model we created last time:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "21apfMGTnquH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "cnn_path = F\"/content/gdrive/My Drive/cnn.zip\"\n",
        "\n",
        "with zipfile.ZipFile(cnn_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bZNwh4tmvn5",
        "outputId": "91996e25-6d93-41eb-cdb0-4478f892e4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can set it to model and double check its shape."
      ],
      "metadata": {
        "id": "o9j7yvdXNzOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your model\n",
        "model = # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "xxSscLB7v02u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instructor Solution\n",
        "tf.keras.models.load_model('cnn')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VHGIT5heXScD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqtYap1OwPcr",
        "outputId": "113bebc8-f886-46a7-c4da-8a9ff0988bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_35 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               2097280   \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,124,993\n",
            "Trainable params: 2,124,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Accept file uploads\n",
        "\n",
        "We want to allow the user of the website to upload their own images to our website for our model to make predictions on. This can be accomplished by the following line:\n",
        "\n",
        "`f = st.file_uploader(\"Upload Image\")`\n",
        "\n",
        "We can then extract and display with the following lines of code\n",
        "\n",
        "```\n",
        "if f is not None:\n",
        "  file_bytes = np.asarray(bytearray(f.read()), dtype=np.uint8)\n",
        "  image = cv2.imdecode(file_bytes, 1)\n",
        "  st.image(image, channels=\"BGR\")\n",
        "```\n",
        "\n",
        "Exercise: Add this code to app.py, run the website and try it out!\n",
        "\n",
        "Hint: Dont forget to\n",
        "\n",
        "`import numpy as np`\n",
        "\n",
        "and\n",
        "\n",
        "`import cv2`\n",
        "\n",
        "at the top of the file."
      ],
      "metadata": {
        "id": "jG7GJI1MwgLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import zipfile\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Extract the CNN model from the zip file\n",
        "cnn_path = \"/content/gdrive/My Drive/cnn.zip\"\n",
        "with zipfile.ZipFile(cnn_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "# Load the CNN model\n",
        "cnn = # YOUR CODE HERE\n",
        "\n",
        "# Create a Title\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Function to process the uploaded image into a format that the model can use\n",
        "def process_image(image):\n",
        "    # Convert the image to RGB mode\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "    # Resize the image\n",
        "    image = image.resize((64, 64))\n",
        "\n",
        "    # Convert the image to an array and normalize\n",
        "    img_array = np.array(image).astype('float32')\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Expand dimensions to match the expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# Display the image upload widget using st.file_uploader\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Perform prediction and display the result\n",
        "if uploaded_file is not None:\n",
        "    # Read the uploaded image\n",
        "    image = Image.open(YOUR CODE HERE)\n",
        "\n",
        "    # Process and classify the image\n",
        "    processed_image = YOUR CODE HERE\n",
        "    prediction = YOUR CODE HERE\n",
        "    diagnoses = YOUR CODE HERE\n",
        "    pred_diagnosis = YOUR CODE HERE\n",
        "\n",
        "    # Display the processed image\n",
        "    YOUR CODE HERE\n",
        "\n",
        "    # Display the predicted diagnosis\n",
        "    st.header(\"Prediction\")\n",
        "    st.subheader(\"Diagnosis\")\n",
        "    st.write(pred_diagnosis)\n"
      ],
      "metadata": {
        "id": "_3UUT4u_OKPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instructor Solution\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import zipfile\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Extract the CNN model from the zip file\n",
        "cnn_path = \"/content/gdrive/My Drive/cnn.zip\"\n",
        "with zipfile.ZipFile(cnn_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "# Load the CNN model\n",
        "cnn = tf.keras.models.load_model('cnn')\n",
        "\n",
        "# Define the Streamlit app\n",
        "st.title(\"Medical Imaging\")\n",
        "\n",
        "# Function to process and classify the uploaded image\n",
        "def process_image(image):\n",
        "    # Convert the image to RGB mode\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "    # Resize the image\n",
        "    image = image.resize((64, 64))\n",
        "\n",
        "    # Convert the image to an array and normalize\n",
        "    img_array = np.array(image).astype('float32')\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Expand dimensions to match the expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# Display the image upload widget\n",
        "uploaded_file = st.file_uploader(\"Select Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "# Perform prediction and display the result\n",
        "if uploaded_file is not None:\n",
        "    # Read the uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "\n",
        "    # Process and classify the image\n",
        "    processed_image = process_image(image)\n",
        "    prediction = cnn.predict(processed_image)\n",
        "    prediction_label = (prediction > 0.5).astype(int)\n",
        "    diagnosis = \"Pneumonia\" if prediction_label else \"No Pneumonia\"\n",
        "\n",
        "    # Display the processed image\n",
        "    st.image(image)\n",
        "\n",
        "    # Display the predicted diagnosis\n",
        "    st.header(\"Prediction\")\n",
        "    st.subheader(\"Diagnosis\")\n",
        "    st.write(diagnosis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMQJpGnFFQ1d",
        "outputId": "ebdb9c11-777a-43c3-f0e5-fcd89b182251",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While running your site, you can try fetching some images from our original dataset below. You can download the image by right-clicking the generated image and `Save image as...` before uploading it to your site!"
      ],
      "metadata": {
        "id": "NqcAZeUZsNNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fetch Image { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Load the image data\n",
        "image_data = np.load('image_data.npy')\n",
        "\n",
        "# Load the metadata\n",
        "metadata = pkg.get_metadata(metadata_path, ['train', 'test'])\n",
        "\n",
        "# Choose an index to download the corresponding image\n",
        "input_index = \"4\" #@param {type:\"string\"}\n",
        "index = int(input_index)\n",
        "\n",
        "# Get the image from the data array\n",
        "image = image_data[index]\n",
        "\n",
        "# Remove the extra channel if it exists\n",
        "if image.shape[-1] == 4:\n",
        "    image = image[:, :, :3]\n",
        "\n",
        "# Create a PIL image object\n",
        "pil_image = Image.fromarray(np.uint8(image))\n",
        "\n",
        "# Get the label for the image using the metadata\n",
        "label = metadata.iloc[index]['class']  # Replace 'class' with the appropriate column name in your metadata\n",
        "if label == 0:\n",
        "    label = 'No Pneumonia'\n",
        "else:\n",
        "    label = 'Pneumonia'\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title('Image')\n",
        "plt.show()\n",
        "\n",
        "# Print the label to the terminal\n",
        "print(f'Label: {label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Q6-67Rs_QYA4",
        "outputId": "deefae3a-0954-495b-bee0-1f98b72e652f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: Pneumonia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "#Publish Web App (Run this again whenever you make changes)\n",
        "launch_website()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgWjdatpFYzl",
        "outputId": "a5085f3b-c3b1-485b-f006-e129f538c6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-07-14T17:00:24+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://bdc2-35-229-156-49.ngrok-free.app\" -> \"http://localhost:80\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:80\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.229.156.49:80\u001b[0m\n",
            "\u001b[0m\n",
            "2023-07-14 17:00:43.145669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (Optional, if time permits) Spend some time thinking about better ways to visualize and use the model, and update app.py"
      ],
      "metadata": {
        "id": "mqLHpRwyXjSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import zipfile\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Extract the CNN model from the zip file\n",
        "cnn_path = \"/content/gdrive/My Drive/cnn.zip\"\n",
        "with zipfile.ZipFile(cnn_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "# Load the CNN model\n",
        "cnn = # YOUR CODE HERE\n",
        "\n",
        "# Create a Title\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Function to process the uploaded image into a format that the model can use\n",
        "def process_image(image):\n",
        "    # Convert the image to RGB mode\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "    # Resize the image\n",
        "    image = image.resize((64, 64))\n",
        "\n",
        "    # Convert the image to an array and normalize\n",
        "    img_array = np.array(image).astype('float32')\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Expand dimensions to match the expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# Display the image upload widget using st.file_uploader\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Perform prediction and display the result\n",
        "if uploaded_file is not None:\n",
        "    # Read the uploaded image\n",
        "    image = Image.open(YOUR CODE HERE)\n",
        "\n",
        "    # Process and classify the image\n",
        "    processed_image = YOUR CODE HERE\n",
        "    prediction = YOUR CODE HERE\n",
        "    diagnoses = YOUR CODE HERE\n",
        "    pred_diagnosis = YOUR CODE HERE\n",
        "\n",
        "    # Display the processed image\n",
        "    YOUR CODE HERE\n",
        "\n",
        "    # Display the predicted diagnosis\n",
        "    st.header(\"Prediction\")\n",
        "    st.subheader(\"Diagnosis\")\n",
        "    st.write(pred_diagnosis)\n"
      ],
      "metadata": {
        "id": "n2JNKkKlFe_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example Solution\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import zipfile\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Extract the CNN model from the zip file\n",
        "cnn_path = \"/content/gdrive/My Drive/cnn.zip\"\n",
        "with zipfile.ZipFile(cnn_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "# Load the CNN model\n",
        "cnn = tf.keras.models.load_model('cnn')\n",
        "\n",
        "# Define the Streamlit app\n",
        "st.title(\"Medical Imaging\")\n",
        "\n",
        "# Function to process and classify the uploaded image\n",
        "def process_image(image):\n",
        "    # Convert the image to RGB mode\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "    # Resize the image\n",
        "    image = image.resize((64, 64))\n",
        "\n",
        "    # Convert the image to an array and normalize\n",
        "    img_array = np.array(image).astype('float32')\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Expand dimensions to match the expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# Display the image upload widget\n",
        "uploaded_file = st.file_uploader(\"Select Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "# Perform prediction and display the result\n",
        "if uploaded_file is not None:\n",
        "    # Read the uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "\n",
        "    # Process and classify the image\n",
        "    processed_image = process_image(image)\n",
        "    prediction = cnn.predict(processed_image)\n",
        "    prediction_label = (prediction > 0.5).astype(int)\n",
        "    diagnosis = \"Pneumonia\" if prediction_label else \"No Pneumonia\"\n",
        "\n",
        "    # Display the processed image\n",
        "    st.image(image)\n",
        "\n",
        "    # Display the predicted diagnosis and confidence score\n",
        "    confidence = prediction[0][0] if prediction_label else 1 - prediction[0][0]\n",
        "    st.header(\"Prediction\")\n",
        "    st.subheader(\"Diagnosis\")\n",
        "    st.write(diagnosis)\n",
        "    st.subheader(\"Confidence Score\")\n",
        "    st.write(f\"{confidence * 100:.2f}%\")\n",
        "\n",
        "    # Get the output of intermediate layers\n",
        "    intermediate_layer_model = tf.keras.models.Model(inputs=cnn.input, outputs=cnn.layers[3].output)\n",
        "    intermediate_output = intermediate_layer_model.predict(processed_image)\n",
        "\n",
        "# Display the model architecture\n",
        "st.subheader(\"Model Architecture\")\n",
        "st.text(cnn.summary())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "agFLl7VhbxPQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}