{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/htn5400/Pneumonia-Detection/blob/main/Section2_PneumoniaDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3veiK-TXoGSV"
      },
      "source": [
        "Let's advance from our baseline models to instead use neural networks for pneumonia detection. We'll practice creating toy neural networks, apply neural networks (including Convolutional Neural Nets!) to our pneumonia data, and experiment with *transfer learning*: learning from an existing \"expert network\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsa9kzHFh4yU"
      },
      "source": [
        "In this notebook we'll be:\n",
        "1.   Building Neural Networks with Keras\n",
        "2.   Implementing Transfer Learning\n",
        "3.   Evalulating our ML models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSeClkWgIORK"
      },
      "source": [
        "#@title Run this to download data and prepare our environment! { display-mode: \"form\" }\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "import keras.optimizers as optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, InputLayer, Reshape, Dense, Conv2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.densenet import DenseNet121\n",
        "\n",
        "\n",
        "class pkg:\n",
        "  #### DOWNLOADING AND LOADING DATA\n",
        "  def get_metadata(metadata_path, which_splits = ['train', 'test']):\n",
        "    '''returns metadata dataframe which contains columns of:\n",
        "       * index: index of data into numpy data\n",
        "       * class: class of image\n",
        "       * split: which dataset split is this a part of?\n",
        "    '''\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    keep_idx = metadata['split'].isin(which_splits)\n",
        "    return metadata[keep_idx]\n",
        "\n",
        "  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n",
        "    '''\n",
        "    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n",
        "    flattens if flatten option is True\n",
        "    '''\n",
        "    sub_df = metadata[metadata['split'].isin([split_name])]\n",
        "    index  = sub_df['index'].values\n",
        "    labels = sub_df['class'].values\n",
        "    data = all_data[index,:]\n",
        "    if flatten:\n",
        "      data = data.reshape([-1, np.product(image_shape)])\n",
        "    return data, labels\n",
        "\n",
        "  def get_train_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('train', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_test_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('test', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "class helpers:\n",
        "  #### PLOTTING\n",
        "  def plot_one_image(data, labels = [], index = None, image_shape = [64,64,3]):\n",
        "    '''\n",
        "    if data is a single image, display that image\n",
        "\n",
        "    if data is a 4d stack of images, display that image\n",
        "    '''\n",
        "    num_dims   = len(data.shape)\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    # reshape data if necessary\n",
        "    if num_dims == 1:\n",
        "      data = data.reshape(target_shape)\n",
        "    if num_dims == 2:\n",
        "      data = data.reshape(np.vstack[-1, image_shape])\n",
        "    num_dims   = len(data.shape)\n",
        "\n",
        "    # check if single or multiple images\n",
        "    if num_dims == 3:\n",
        "      if num_labels > 1:\n",
        "        print('Multiple labels does not make sense for single image.')\n",
        "        return\n",
        "\n",
        "      label = labels\n",
        "      if num_labels == 0:\n",
        "        label = ''\n",
        "      image = data\n",
        "\n",
        "    if num_dims == 4:\n",
        "      image = data[index, :]\n",
        "      label = labels[index]\n",
        "\n",
        "    # plot image of interest\n",
        "    print('Label: %s'%label)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "  def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    # i'm sorry for this function's code. i am so sorry.\n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')\n",
        "    ax.legend(loc = 4)\n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "class models:\n",
        "  def DenseClassifier(hidden_layer_sizes, nn_params):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape = nn_params['input_shape']))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    for ilayer in hidden_layer_sizes:\n",
        "      model.add(Dense(ilayer, activation = 'relu'))\n",
        "      model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer= keras.optimizers.SGD(learning_rate=1e-4, momentum=0.95),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def CNNClassifier(num_hidden_layers, nn_params):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=nn_params['input_shape'], padding = 'same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    for i in range(num_hidden_layers-1):\n",
        "        model.add(Conv2D(64, (3, 3), padding = 'same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(units = 128, activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units = 64, activation = 'relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.legacy.RMSprop(learning_rate=1e-5, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def TransferClassifier(name, nn_params, trainable = False):\n",
        "    expert_dict = {'VGG16': VGG16,\n",
        "                   'VGG19': VGG19,\n",
        "                   'ResNet50':ResNet50,\n",
        "                   'DenseNet121':DenseNet121}\n",
        "\n",
        "    expert_conv = expert_dict[name](weights = 'imagenet',\n",
        "                                              include_top = False,\n",
        "                                              input_shape = nn_params['input_shape'])\n",
        "    for layer in expert_conv.layers:\n",
        "      layer.trainable = trainable\n",
        "\n",
        "    expert_model = Sequential()\n",
        "    expert_model.add(expert_conv)\n",
        "    expert_model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    expert_model.add(Dense(128, activation = 'relu'))\n",
        "    # expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(64, activation = 'relu'))\n",
        "    # expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    expert_model.compile(loss = nn_params['loss'],\n",
        "                  optimizer = keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return expert_model\n",
        "\n",
        "### defining project variables\n",
        "# file variables\n",
        "metadata_url         = \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/metadata.csv\"\n",
        "image_data_url       = 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/image_data.npy'\n",
        "image_data_path      = './image_data.npy'\n",
        "metadata_path        = './metadata.csv'\n",
        "image_shape          = (64, 64, 3)\n",
        "\n",
        "# neural net parameters\n",
        "nn_params = {}\n",
        "nn_params['input_shape']       = image_shape\n",
        "nn_params['output_neurons']    = 1\n",
        "nn_params['loss']              = 'binary_crossentropy'\n",
        "nn_params['output_activation'] = 'sigmoid'\n",
        "\n",
        "###\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/metadata.csv\"\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/image_data.npy\"\n",
        "\n",
        "### pre-loading all data of interest\n",
        "_all_data = np.load('image_data.npy')\n",
        "_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n",
        "\n",
        "### preparing definitions\n",
        "# downloading and loading data\n",
        "get_data_split = pkg.get_data_split\n",
        "get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n",
        "get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "\n",
        "# plotting\n",
        "plot_one_image = lambda data, labels = [], index = None: helpers.plot_one_image(data = data, labels = labels, index = index, image_shape = image_shape);\n",
        "plot_acc       = lambda history: helpers.plot_acc(history)\n",
        "\n",
        "# models with input parameters\n",
        "DenseClassifier     = lambda hidden_layer_sizes: models.DenseClassifier(hidden_layer_sizes = hidden_layer_sizes, nn_params = nn_params);\n",
        "CNNClassifier       = lambda num_hidden_layers: models.CNNClassifier(num_hidden_layers, nn_params = nn_params);\n",
        "TransferClassifier  = lambda name: models.TransferClassifier(name = name, nn_params = nn_params);\n",
        "\n",
        "monitor = ModelCheckpoint('./model.h5', monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-hvosCRrBGu"
      },
      "source": [
        "## Instructor-led Discussion: Steps for Building a NN in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYqvCKWpKfRM"
      },
      "source": [
        "### What are neural networks?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA1Rc_u3KoJT"
      },
      "source": [
        "Just as we went over last week, neural networks look something like this:\n",
        "![A 2 layer neural network](https://cdn-images-1.medium.com/max/1600/1*DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q9S6SDcM8N9"
      },
      "source": [
        "Each orange and blue node is a neuron. The network itself is composed of a bunch of neurons that talk to each other and eventually give us a prediction. Let's get a bit more concrete with this..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E--8mjToZYBp"
      },
      "source": [
        "To build neural networks in Python, we use the packages known as `tensorflow` and `keras`. Let's learn how to build and use these networks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqFAnQCxsgRm"
      },
      "source": [
        "# grab tools from our tensorflow and keras toolboxes!\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
        "from keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq4G0hDwZKnM"
      },
      "source": [
        "## Exercise (Coding): A 2-Layer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj-Pt3wGCXRu"
      },
      "source": [
        "\n",
        "We're going to build this model:\n",
        "\n",
        "![](http://cs231n.github.io/assets/nn1/neural_net.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-6WGeedvTCS"
      },
      "source": [
        "This network can be described as:\n",
        "* **Input Layer**: 3 neurons\n",
        "* **Layer 1 (Hidden)**: 4 neurons with the `'relu'` activation function\n",
        "* **Layer 2 (Output)**: 2 neurons with the `'softmax'` activation function\n",
        "\n",
        "We're going to set up a **Sequential** model by adding on a sequence of layers. We will also have **Dense** layers, meaning each neuron of the previous layer connects to each neuron of this layer.\n",
        "\n",
        "We'll compile our model to make it ready to use! We'll use:\n",
        "- `loss = 'categorical_crossentropy'` (how to measure the model's performance while it trains)\n",
        "- `optimizer = 'adam'` (an algorithm for adjusting the weights)\n",
        "- `metric = 'accuracy'` (how to measure the model's performance at the end)\n",
        "\n",
        "Try it out below!\"\n",
        "\n",
        "The information about the `input_shape` parameter has been added to clarify the input data's expected shape for the first layer. This parameter plays a crucial role in defining the model's architecture and ensuring that the subsequent layers receive data with the correct dimensions.\n",
        "\n",
        "*Hint: Look back to your CNN Notebook to check the syntax for this code!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zgA-wPfvCyK"
      },
      "source": [
        "# Fill in the blanks with your group!\n",
        "### YOUR CODE HERE:\n",
        "model_1 = Sequential()\n",
        "model_1.add(InputLayer(input_shape=(____,)))\n",
        "model_1.add(Dense(____, activation = '____'))\n",
        "model_1.add(Dense(____, activation = '____'))\n",
        "model_1.compile(loss='_____',\n",
        "                optimizer = 'adam',\n",
        "                metrics = ['accuracy'])\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlVFP9lhJed-"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "# Fill in the blanks with your group!\n",
        "### YOUR CODE HERE:\n",
        "model_1_answer = Sequential()\n",
        "model_1_answer.add(InputLayer(input_shape=(3,)))\n",
        "model_1_answer.add(Dense(4, activation = 'relu'))\n",
        "model_1_answer.add(Dense(2, activation = 'softmax'))\n",
        "model_1_answer.compile(loss='categorical_crossentropy',\n",
        "                       optimizer = 'adam',\n",
        "                       metrics = ['accuracy'])\n",
        "\n",
        "model_1 = model_1_answer\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK_lyjxGpwv3",
        "cellView": "form"
      },
      "source": [
        "#@title Double-click here if you want to read more detail!\n",
        "\"\"\"\n",
        "Let's walk though what each of these lines of code means!\n",
        "\n",
        "**1. Specify model**\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "```\n",
        "In this line of code, we build our network where the information flows from LEFT to RIGHT through the network in ONE DIRECTION as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it.\n",
        "\n",
        "\n",
        "**2. Add layers to the network**\n",
        "```\n",
        "model.add(Dense(4,input_shape = (3,), activation = 'softmax'))\n",
        "```\n",
        "In this code, we `add` a `layer` of neurons to our network.\n",
        "\n",
        "This layers consists of 4 neurons. Each neuron is DENSE and connects to all of the previous layer's inputs and all of the subsequent layers outputs. We specify that there are 3 inputs here.\n",
        "\n",
        "We also specify what kind of output the neuron will give. If you want the neuron to output a number between 0 and 1 (like a probability!) you would use 'softmax' or 'softmax'. If you want the neuron to output any number, you can use 'linear'! You'll also often see 'relu', which is when a neuron will only output positive numbers.\n",
        "\n",
        "```\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "```\n",
        "This code adds ANOTHER layer to the network that has 1 neuron. This one neuron is used to predict a continuous value!\n",
        "\n",
        "**3. Turn the model on by compiling it**\n",
        "\n",
        "After having built the network, we want to train and use it, so we have to 'turn it on' and 'compile' it. To turn it on, we have to specify at the very least, a loss, an optimizer, and some ways of evaluating the model (metrics). Don't worry too much about what this means! Just know that this is necessary.\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error',\n",
        "optimizer = 'adam',\n",
        "metrics = ['mean_squared_error'])\n",
        "  ```\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH2UGOK4vuZ4"
      },
      "source": [
        "#@title Run this to test if your model is right!\n",
        "model_1_answer = Sequential()\n",
        "model_1_answer.add(InputLayer(input_shape=(3,)))\n",
        "model_1_answer.add(Dense(4, activation = 'relu'))\n",
        "model_1_answer.add(Dense(2, activation = 'softmax'))\n",
        "model_1_answer.compile(loss='categorical_crossentropy',\n",
        "optimizer = 'adam',\n",
        "metrics = ['accuracy'])\n",
        "\n",
        "model_1_config = model_1.get_config()\n",
        "\n",
        "del model_1_config[\"name\"]\n",
        "for layer in model_1_config[\"layers\"]:\n",
        "  del layer[\"config\"][\"name\"]\n",
        "\n",
        "model_1_answer_config = model_1_answer.get_config()\n",
        "\n",
        "del model_1_answer_config[\"name\"]\n",
        "for layer in model_1_answer_config[\"layers\"]:\n",
        "  del layer[\"config\"][\"name\"]\n",
        "\n",
        "if model_1_answer_config == model_1_config:\n",
        "  print('Good job! Your model worked')\n",
        "else:\n",
        "  print('Please check your code again!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNBg8obslWlo"
      },
      "source": [
        "This is a toy example, so we won't train our model with real data - but we can feed in some fake inputs to see what happens! **How many inputs do we need?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE_C03CplcyY"
      },
      "source": [
        "input_data = [[   ]] #Fill in inputs here! How many?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBfMgsO5mwlp",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "input_data = [[3,4,3]] #Fill in inputs here! How many?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJMbtRllotiY"
      },
      "source": [
        "Let's try it out! What does **predict** do? How do you interpret the outputs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIiU4_ngotGh"
      },
      "source": [
        "print(model_1.predict(input_data))\n",
        "print((model_1.predict(input_data) > 0.5).astype(\"int32\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypsWJtgSl_OJ"
      },
      "source": [
        "**How many outputs** are there? How would you interpret them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9CmrRkgT5ZS"
      },
      "source": [
        "# Milestone 2. Exploring Neural Networks\n",
        "\n",
        "Now, let's apply neural networks to our medical imaging problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD3Z0QamJF68"
      },
      "source": [
        "\n",
        "In our problem, we are given `images` of shape `(64,64,3)`, each assigned a label **pneumonia** or **healthy**. We want to identify the key things that we need to design our network.\n",
        "\n",
        "In your group, discuss:\n",
        "\n",
        "* What are our inputs?\n",
        "* What is/are our outputs?\n",
        "\n",
        "How could this look in a neural network diagram?\n",
        "\n",
        "**Brainstorm and sketch out a neural network that would work for this problem, and share with the group!**\n",
        "\n",
        "**Optional Exercise:** Following the setup from Notebook 1, create and test a neural network using Scikit-learn for this problem. [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) gives you a simple neural network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2fStUprqjmY"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "X_train, y_train = get_train_data(flatten = True)\n",
        "X_test, y_test = get_test_data(flatten = True)\n",
        "\n",
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYm6_QGUqmTN",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "X_train, y_train = get_train_data(flatten = True)\n",
        "X_test, y_test = get_test_data(flatten = True)\n",
        "clf = MLPClassifier(hidden_layer_sizes=(5))\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0xP2sDhOf4M"
      },
      "source": [
        "## Activity 2a. Challenging pneumonia with our models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47bngTjCT_pM"
      },
      "source": [
        "Now, let's try out 'Convolutional Neural Networks'! Convolutional neural networks are networks that process images much like our visual system does. We'll use a Keras wrapper that abstracts away the details - talk to your instructor if you're interested in exploring CNN with more details!\n",
        "\n",
        "First, let's get our data. **Why do we not use flattened data for CNNs?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeA8gWV6sqai"
      },
      "source": [
        "X_train, y_train = get_train_data()\n",
        "X_test, y_test = get_test_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01ayM3u3sXA-"
      },
      "source": [
        "### Creating Models\n",
        "Now, let's create a model! In fact, let's create two:\n",
        "\n",
        "\n",
        "For a \"vanilla\" neural network:\n",
        "\n",
        "```\n",
        "dense = DenseClassifier(hidden_layer_sizes = (64,32))\n",
        "```\n",
        "* hidden_layer_sizes: the number of neurons in each hidden layer\n",
        "* epochs: the number of times that our network trains on all of the training data\n",
        "\n",
        "\n",
        "For a convolutional neural network:\n",
        "```\n",
        "cnn = CNNClassifier(num_hidden_layers = 1)\n",
        "```\n",
        "* num_hidden_layers: the number of hidden layers\n",
        "\n",
        "**Create your models below!** Use any hidden layer sizes you like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTb16LvwtGNW"
      },
      "source": [
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1QMuD5ttS7T",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "dense = DenseClassifier(hidden_layer_sizes = (64,32))\n",
        "cnn = CNNClassifier(num_hidden_layers = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFymjNnsNPC"
      },
      "source": [
        "### Fitting and Scoring\n",
        "Now, let's fit  our models!\n",
        "\n",
        "There are default parameters to `.fit` you can call:\n",
        "\n",
        "```\n",
        "model_history = model.fit(X_train, y_train, epochs = 100, validation_data = (X_test, y_test), shuffle = True, callbacks = [monitor])\n",
        "```\n",
        "\n",
        "The `shuffle` parameter is important for shuffling the training data before each epoch. The `monitor` callback is used to get a view on internal states and statistics of the model during training. Please don't change these parameters!\n",
        "\n",
        "**Fit your models below!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUgtK9n6t2CU"
      },
      "source": [
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC8fahXDthI4"
      },
      "source": [
        "#@title Instructor Solution\n",
        "dense_history = dense.fit(X_train, y_train, epochs = 50, validation_data = (X_test, y_test), shuffle = True, callbacks = [monitor])\n",
        "cnn_history = cnn.fit(X_train, y_train, epochs = 50, validation_data = (X_test, y_test), shuffle = True, callbacks = [monitor])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NbTRTFluCNt"
      },
      "source": [
        "**Can you interpret the numbers displayed? Which do you care about most?**\n",
        "\n",
        "*Hint*: \"validation set\" is similar to \"test set\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlYo20_lttEA"
      },
      "source": [
        "###Scoring\n",
        "\n",
        "Now, let's evaluate our models! To get the scores, you can use:\n",
        "```\n",
        "score = model.evaluate(X_test, y_test)\n",
        "```\n",
        "\n",
        "Then `score[0]` will be test loss and `score[1]` will be test accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tywOuLnPucIC"
      },
      "source": [
        "#YOUR CODE HERE to score your models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm4EET7BuepO"
      },
      "source": [
        "#@title Instructor Solution\n",
        "cnn_score = cnn.evaluate(X_test, y_test)\n",
        "dense_score = dense.evaluate(X_test, y_test)\n",
        "print (cnn_score)\n",
        "print (dense_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jakb5j_Hux7W"
      },
      "source": [
        "**Which model did better? Any surprises?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozaEE78ktkyw"
      },
      "source": [
        "### Plotting\n",
        "\n",
        "A great way to understand our model better is to plot the training and test accuracy over time with `plot_acc(model_history)`.\n",
        "\n",
        "**What do you observe of the training and test accuracy over the training epochs?**\n",
        "\n",
        "Discuss this with your group and your instructor! What problems are we experiencing? How can we fix them?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nBfrnjIXzdp"
      },
      "source": [
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWtppCPbvK7M"
      },
      "source": [
        "#@title Instructor Solution\n",
        "plot_acc(dense_history)\n",
        "plot_acc(cnn_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3wqKrSyVBqr"
      },
      "source": [
        "## Instructor-Led Discussion: Overfitting\n",
        "\n",
        "**Questions:**\n",
        "Was the best epoch necessarily the last epoch?\n",
        "\n",
        "You should check what the best epoch was at every step of the way!\n",
        "\n",
        "**When does your model overfit? How could we fix it?**\n",
        "\n",
        "**Experiment with different network structures** before you move on!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5scKiYAYE8g"
      },
      "source": [
        "\n",
        "# Milestone 3. Expert models: Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FybhlxdVYFbv"
      },
      "source": [
        "\n",
        "## Instructor-Led Discussion: Transfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bx5nyzE36EQ"
      },
      "source": [
        "So far, we've used models that were built from 'scratch'. Unfortunately, our training data is small relative to the amount of data available in the real world, so just training on our dataset is going to be inherently limited.\n",
        "\n",
        "Luckily, there are **expert models**, or state-of-the-art models that have been trained by the world's top researchers! While these expert models haven't trained on our training data, they have trained extensively on larger datasets. We can input our data and reasonably expect that they will pick up our task fairly quickly.\n",
        "\n",
        "In deep learning, the idea of using a model trained on another task as a starting point for your model is known as **transfer learning**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DChmzlt3ARPy"
      },
      "source": [
        "### VGG 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFtHOYI2AdSs"
      },
      "source": [
        "For our transfer learning, we're going to use 'experts' built upon the famous 'ImageNet' classification problem.\n",
        "\n",
        "In ImageNet, participants were challenged to build machine learning models that could distinguish 14 million images' categories, where there were > 20,000 categories available.\n",
        "\n",
        "Below, we see examples of 4 different categories.\n",
        "\n",
        "![](http://cs231n.github.io/assets/trainset.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-E_AiG-CFj0"
      },
      "source": [
        "One of the experts we can use is VGG16. VGG16 is a specific convolutional neural network that was allowed to study the 14 million images 74 times. *(Read more about VGG16 [here!](https://neurohive.io/en/popular-networks/vgg16/))*\n",
        "\n",
        "After training, VGG16 was able to guess something close to the real label (top-5 accuracy) better than a human can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvkajtdHAbzL"
      },
      "source": [
        "![](https://cdn-images-1.medium.com/max/1600/0*V1muWIDnPVwZUuEv.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwj8o5X3D325"
      },
      "source": [
        "We're going to take an expert model like VGG16 and let it train on OUR x-rays. Hopefully, its experience with those 14 million images will help it differentiate between healthy and pneumonia-affected x-rays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-357WWC7qJJ"
      },
      "source": [
        "### Exercise (Coding) | Within a student group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz_mVsECHvro"
      },
      "source": [
        "Let's tap an expert model to help us out with our pneumonia prediction!\n",
        "\n",
        "We provide a wrapper that lets you 'call' up and employ expert models. You can call it like...\n",
        "\n",
        "```\n",
        "transfer = TransferClassifier(name = 'VGG16')\n",
        "```\n",
        "\n",
        "The experts we have on hand are:\n",
        "* `VGG16`\n",
        "* `VGG19`\n",
        "* `ResNet50`\n",
        "* `DenseNet121`\n",
        "\n",
        "There are default parameters to model.fit you can call:\n",
        "\n",
        "`model.fit(X_train, y_train, epochs = N, validation_data = (X_test, y_test), shuffle = True, callbacks = [monitor])`\n",
        "\n",
        "The `shuffle` parameter is important for shuffling the training data before each epoch. The `[monitor]` callback is used to get a view on internal states and statistics of the model during training. Do not change these parameters!\n",
        "\n",
        "**Please experiment with using these experts! Remember to fit and score your model, and to take a look at the training history.**\n",
        "\n",
        "How many epochs do you need now?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VB79BCx7tvg"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbHqc9sVEPMo"
      },
      "source": [
        "#@title Instructor Solution { display-mode: \"form\" }\n",
        "X_train, y_train = get_train_data()\n",
        "X_test, y_test = get_test_data()\n",
        "transfer = TransferClassifier(name = 'DenseNet121')\n",
        "transfer.fit(X_train, y_train, epochs = 25, validation_data = (X_test, y_test), shuffle = True, callbacks = [monitor])\n",
        "plot_acc(transfer.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9Qp129rNV3U"
      },
      "source": [
        "# Milestone 4\n",
        "## Instructor-led Discussion: Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwERVb37ylko"
      },
      "source": [
        "## Activity 4a. How did we do on pneumonia prediction?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXyQLXigDbtg"
      },
      "source": [
        "\n",
        "\n",
        "### Exercise (Coding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBbSwkgVj7gS"
      },
      "source": [
        "Set your best model to the one you have trained (e.g., the transfer learning model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmjOJCGDjsMk"
      },
      "source": [
        "best_model = transfer ## Change this if another model did better!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBhDGS02VGHa"
      },
      "source": [
        "As we learned last week, total accuracy does not reflect all that we want to know about a model's performance. It's just one metric out of many possible metrics for evaluating models.\n",
        "\n",
        "In the case of pneumonia prediction, we may be more interested in other quantities, such as 'how accurate were we on the pneumonia category?' or 'how accurate were we on the healthy category?' or 'how much of pneumonia were confused for healthy?' or vice versa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_GjNUEBMSke"
      },
      "source": [
        "Our metrics for classification can be described in terms of a 'confusion matrix', shown below.\n",
        "\n",
        "![Confusion Matrix](https://cdn-images-1.medium.com/max/1600/1*Z54JgbS4DUwWSknhDCvNTQ.png)\n",
        "\n",
        "In a confusion matrix, we think in terms of 'actual' and 'predicted values'. If we take Pneumonia = 1/Positive and Normal = 0/Negative, then **what do TP, FP, TN, and FN mean?**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuZI17S_wGUv"
      },
      "source": [
        "#@title Solution\n",
        "# True positive: True pneumonia: Pneumonia predicted as pneumonia\n",
        "# True negative: True normal: Normal predicted as normal\n",
        "# False positive: False pneumonia: Normal mistaken as pneumonia\n",
        "# False negative: False normal: Pneumonia mistaken as normal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL0ns-b9GBym"
      },
      "source": [
        "The `sklearn` package makes calculating confusion matrices very quick! Its `metrics` submodule actually comes with a `confusion_matrix` tool. Let's start by grabbing that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2E5299cNEcp"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvFawPv1NIyy"
      },
      "source": [
        "To use `confusion_matrix`, we need:\n",
        "* `labels`: the labels of the data (1 - PNEUMONIA or 0 - NORMAL)\n",
        "* `predictions`: what our model thinks the labels are\n",
        "\n",
        "To get `predictions`, you'll want to use ```(best_model.predict(X_test) > 0.5).astype(\"int32\")```.\n",
        "\n",
        "Please get the `predictions`, and use `accuracy_score` to print the overall test accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke5_OhU1wlpU"
      },
      "source": [
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cLkk9eJkI3I"
      },
      "source": [
        "#@title Instructor Solution\n",
        "y_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "print('Accuracy: ', accuracy_score(y_test, y_pred)*100.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcFGwTMDkCAp"
      },
      "source": [
        "Now let's get our confusion matrix, and split it out into true positive, true negative, false positive, and false negative!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7omQvlbkSTn"
      },
      "source": [
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print(confusion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zQjmPA4w8wJ"
      },
      "source": [
        "**How do you interpret each number?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K17HWY9Iw3gA"
      },
      "source": [
        "tp  = confusion[1][1]\n",
        "tn  = confusion[0][0]\n",
        "fp = confusion[0][1]\n",
        "fn = confusion[1][0]\n",
        "\n",
        "print('True positive: %d'%tp)\n",
        "print('True negative: %d'%tn)\n",
        "print('False positive: %d'%fp)\n",
        "print('False negative: %d'%fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKlghw6_krXL"
      },
      "source": [
        "We can visualize the confusion matrix with seaborn to make it easier for our eyes..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Cp60eokseD"
      },
      "source": [
        "# grab our plotting package\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Jwv2-OktLb"
      },
      "source": [
        "sns.heatmap(confusion, annot = True, fmt = 'd', cbar_kws={'label':'count'});\n",
        "plt.ylabel('Actual');\n",
        "plt.xlabel('Predicted');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFj6JvhMxAwX"
      },
      "source": [
        "**What do you notice about this confusion matrix?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdnF7l8_khHU"
      },
      "source": [
        "## Instructor-Led Discussion: Comparing False Positives and False Negatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Tt6kTRkTvm"
      },
      "source": [
        "**Now that we have our confusion matrix, let's take a step back and discuss**\n",
        "\n",
        "What did our model confuse more?\n",
        "* PNEUMONIA for NORMAL or...\n",
        "* NORMAL for PNEUMONIA\n",
        "\n",
        "Why do you think it might have confused one for the other?\n",
        "\n",
        "**Discuss with your instructor what you got and also...**\n",
        "\n",
        "What is more problematic? False positives or False negatives?\n",
        "\n",
        "Which of these metrics do we want to keep low?\n",
        "\n",
        "**Optional challenge exercises:**\n",
        "- Create a function to calculate [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall). Which one do you care about more?\n",
        "- Experiment with your models to find one that optimizes for what you care about, not just accuracy!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8KmugJ_N9BQ"
      },
      "source": [
        "# Fin!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV85QOOGQ2xm"
      },
      "source": [
        "To recap, we built neural network models to see if we can do better than our baseline models performed. It turns out that we can! And, also, by introducing convolutions to our networks (making the convolutional neural networks), we can improve by quite a lot. Finally, we employed pretrained 'expert' models to boost our performance even further.\n",
        "\n",
        "In the next section, we'll test out our models on actual field data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14rKID6MOo4N"
      },
      "source": [
        "![](https://storage.googleapis.com/kaggle-competitions/kaggle/10338/logos/header.png)"
      ]
    }
  ]
}